**7/5**
- load_SP 함수를 완전히 작성. 디버깅은 필요.
- 좌표값을 x로 두는게 아니라, 따로 값을 만들었다. 


**7/6**
- 시뮬레이션에서 n_train,n,p로 하는게 이상하다는 것을 알아냈다. CNN이면 괜찮은데, DNN이라서 n_train,p의 형태가 되어야할 듯 하다. 
- 40개씩 관찰되었음을 가정하고 있는데, 이걸 40개 단위를 없애고 그냥 n_train 개수에 통합시켜도 괜찮을까?
- 아니면 batch_size 단위를 40의 배수로 하는 방법도 있을 듯 하다. 
- 학습은 되는 듯 하다. 이제 testset을 시각화하는 함수를 만들면 될 듯 하다. 시각화를 krigging으로 가볼까?
- 시각화하기 편하게 40개 말고 제곱되는 값으로 만들고 batch size도 맞춰보자. 

**7/8**
- 시각화는 완료했다. 이후에 실제 모델 값과 시각적으로 비교해보자. 
- 길이의 제한을 풀 수 있는 모델의 형태를 생각해보자. (attention 다시 살펴보자.)
- 시뮬레이션이 생성에 오래 걸리니까 따로 만들어놓고 불러와도 된다. 그러면 조금 더 큰 사이즈를 만들어볼 수 있다.  
- 일반적인 DNN으로는 결과가 좋을 수 없을 듯 하다. 
- 다른 모델을 적용시켜야 한다. 후보를 찾아보자. 

**7/10**
- attention 다시 뜯어보는 중. 여기서 input의 길이 제한없이 받아들이는 아이디어를 잡아야 한다. 
- cross attention부터 다시 보자. 

**7/11**
- 그림으로 나와 있는 것보다 훨씬 간단한 형태로 구현이 되어 있는 듯 하다. 
- plotting을 이제 보면 될 듯 하다.(왜 이게 input 길이 제한이 없는지 확인)
- 모델 자체에는 특별한 점이 없는 것으로 보인다. 

**7/12**
- train 시에는 고정된 값으로 훈련을 진행하고, test시에는 batch size 1로 해서 계속 새로 뽑아서 그리는 것으로 확인된다. 
- 결국 train할 때, 충분히 많은 수의 target이 있다.
- target_y가 있을 때는 이를 이용한 posterioir를 구하고, 없을 때는 샘플링해서 이용한다.
- ~여기서도 샘플링이 이용되는 것이라면, 샘플링을 쉽게 해주는 방법으로 뽑으면 안될까?~
- atttention에 weight을 거리로 가중치 주는 것으로 하고, gaussian예제를 생성해서 ANP처럼 해보자. 


**7/18**
- parameter estimation을 한다고 생각하고, attention에 적용시켜서 gaussian process를 해보는 중이다. 
- 실험 세팅에서 batch별로 관찰되는 위치가 계속 달라지는 걸로 세팅이 되어 있는데 이를 고정시켜야할까?
- 일단은 그냥 진행해보는데, 잘 안된다면 이 점을 상기해보자.
- 이렇게 했을 때 장점은, batch 사이즈가 달라도 작동한다는 것이므로, 관찰된 데이터의 개수가 달라도 예측을 해볼 수 있다는 점이다. 

**8/1**
- 일단 좌표를 받아서 모델을 만들어보라고 하셨다.(근데 이게 무슨 의미가 있는 것인지는 잘 모르겠음)
- 그러면서 paper를 주셨는데, 여기서 사용한 방법을 일단 먼저 인지해야할 듯 하다. 